[2022-06-01 05:29:32,133] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: ClusterStartUp.hdfsformat01 2022-06-01T05:29:13.040634+00:00 [queued]>
[2022-06-01 05:29:32,183] {taskinstance.py:826} INFO - Dependencies all met for <TaskInstance: ClusterStartUp.hdfsformat01 2022-06-01T05:29:13.040634+00:00 [queued]>
[2022-06-01 05:29:32,183] {taskinstance.py:1017} INFO - 
--------------------------------------------------------------------------------
[2022-06-01 05:29:32,183] {taskinstance.py:1018} INFO - Starting attempt 1 of 1
[2022-06-01 05:29:32,183] {taskinstance.py:1019} INFO - 
--------------------------------------------------------------------------------
[2022-06-01 05:29:32,214] {taskinstance.py:1038} INFO - Executing <Task(BashOperator): hdfsformat01> on 2022-06-01T05:29:13.040634+00:00
[2022-06-01 05:29:32,216] {standard_task_runner.py:51} INFO - Started process 580 to run task
[2022-06-01 05:29:32,222] {standard_task_runner.py:75} INFO - Running: ['airflow', 'tasks', 'run', 'ClusterStartUp', 'hdfsformat01', '2022-06-01T05:29:13.040634+00:00', '--job-id', '64', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/ClusterStartUp.py', '--cfg-path', '/tmp/tmpiigpjtry']
[2022-06-01 05:29:32,222] {standard_task_runner.py:76} INFO - Job 64: Subtask hdfsformat01
[2022-06-01 05:29:32,374] {logging_mixin.py:103} INFO - Running <TaskInstance: ClusterStartUp.hdfsformat01 2022-06-01T05:29:13.040634+00:00 [running]> on host master01
[2022-06-01 05:29:32,510] {taskinstance.py:1232} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=ClusterStartUp
AIRFLOW_CTX_TASK_ID=hdfsformat01
AIRFLOW_CTX_EXECUTION_DATE=2022-06-01T05:29:13.040634+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-06-01T05:29:13.040634+00:00
[2022-06-01 05:29:32,511] {bash.py:135} INFO - Tmp dir root location: 
 /tmp
[2022-06-01 05:29:32,511] {bash.py:158} INFO - Running command: hdfs namenode -format
[2022-06-01 05:29:32,519] {bash.py:169} INFO - Output:
[2022-06-01 05:29:33,201] {bash.py:173} INFO - 2022-06-01 05:29:33,199 INFO namenode.NameNode: STARTUP_MSG:
[2022-06-01 05:29:33,201] {bash.py:173} INFO - /************************************************************
[2022-06-01 05:29:33,201] {bash.py:173} INFO - STARTUP_MSG: Starting NameNode
[2022-06-01 05:29:33,201] {bash.py:173} INFO - STARTUP_MSG:   host = master01/172.16.238.2
[2022-06-01 05:29:33,201] {bash.py:173} INFO - STARTUP_MSG:   args = [-format]
[2022-06-01 05:29:33,201] {bash.py:173} INFO - STARTUP_MSG:   version = 3.3.1
[2022-06-01 05:29:33,211] {bash.py:173} INFO - STARTUP_MSG:   classpath = /opt/hadoop/current/etc/hadoop:/opt/hadoop/current/share/hadoop/common/lib/accessors-smart-2.4.2.jar:/opt/hadoop/current/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop/current/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop/current/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop/current/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop/current/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop/current/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/current/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/current/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/hadoop/current/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop/current/share/hadoop/common/lib/commons-compress-1.19.jar:/opt/hadoop/current/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/current/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/opt/hadoop/current/share/hadoop/common/lib/commons-io-2.8.0.jar:/opt/hadoop/current/share/hadoop/common/lib/commons-lang3-3.7.jar:/opt/hadoop/current/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/current/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/current/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop/current/share/hadoop/common/lib/commons-text-1.4.jar:/opt/hadoop/current/share/hadoop/common/lib/curator-client-4.2.0.jar:/opt/hadoop/current/share/hadoop/common/lib/curator-framework-4.2.0.jar:/opt/hadoop/current/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/opt/hadoop/current/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop/current/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop/current/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop/current/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop/current/share/hadoop/common/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/current/share/hadoop/common/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/current/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/current/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/current/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/current/share/hadoop/common/lib/httpclient-4.5.13.jar:/opt/hadoop/current/share/hadoop/common/lib/httpcore-4.4.13.jar:/opt/hadoop/current/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop/current/share/hadoop/common/lib/jackson-annotations-2.10.5.jar:/opt/hadoop/current/share/hadoop/common/lib/jackson-core-2.10.5.jar:/opt/hadoop/current/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/current/share/hadoop/common/lib/jackson-databind-2.10.5.1.jar:/opt/hadoop/current/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/current/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/current/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop/current/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/current/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/current/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop/current/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/current/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/current/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop/current/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/hadoop/current/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop/current/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop/current/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop/current/share/hadoop/common/lib/jetty-http-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/common/lib/jetty-io-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/common/lib/jetty-security-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/common/lib/jetty-server-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/common/lib/jetty-servlet-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/common/lib/jetty-util-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/common/lib/jetty-util-ajax-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/common/lib/jetty-webapp-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/common/lib/jetty-xml-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/common/lib/jsch-0.1.55.jar:/opt/hadoop/current/share/hadoop/common/lib/json-smart-2.4.2.jar:/opt/hadoop/current/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/current/share/hadoop/common/lib/jsr305-3.0.2.jar:/opt/hadoop/current/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop/current/share/hadoop/common/lib/jul-to-slf4j-1.7.30.jar:/opt/hadoop/current/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop/current/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop/current/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop/current/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop/current/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/current/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop/current/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop/current/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/current/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop/current/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/current/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop/current/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/current/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop/current/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/current/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/current/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop/current/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop/current/share/hadoop/common/lib/netty-3.10.6.Final.jar:/opt/hadoop/current/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/current/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/current/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/current/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop/current/share/hadoop/common/lib/slf4j-api-1.7.30.jar:/opt/hadoop/current/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/current/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/current/share/hadoop/common/lib/stax2-api-4.2.1.jar:/opt/hadoop/current/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop/current/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/opt/hadoop/current/share/hadoop/common/lib/zookeeper-3.5.6.jar:/opt/hadoop/current/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/opt/hadoop/current/share/hadoop/common/hadoop-common-3.3.1-tests.jar:/opt/hadoop/current/share/hadoop/common/hadoop-common-3.3.1.jar:/opt/hadoop/current/share/hadoop/common/hadoop-kms-3.3.1.jar:/opt/hadoop/current/share/hadoop/common/hadoop-nfs-3.3.1.jar:/opt/hadoop/current/share/hadoop/common/hadoop-registry-3.3.1.jar:/opt/hadoop/current/share/hadoop/hdfs:/opt/hadoop/current/share/hadoop/hdfs/lib/accessors-smart-2.4.2.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/commons-compress-1.19.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/commons-text-1.4.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jackson-annotations-2.10.5.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jackson-core-2.10.5.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jackson-databind-2.10.5.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jetty-http-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jetty-io-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jetty-security-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jetty-server-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jetty-servlet-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jetty-util-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jetty-webapp-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jetty-xml-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/json-smart-2.4.2.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/netty-all-4.1.61.Final.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/opt/hadoop/current/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/opt/hadoop/current/share/hadoop/hdfs/hadoop-hdfs-3.3.1-tests.jar:/opt/hadoop/current/share/hadoop/hdfs/hadoop-hdfs-3.3.1.jar:/opt/hadoop/current/share/hadoop/hdfs/hadoop-hdfs-client-3.3.1-tests.jar:/opt/hadoop/current/share/hadoop/hdfs/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/current/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.1.jar:/opt/hadoop/current/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.1-tests.jar:/opt/hadoop/current/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.1.jar:/opt/hadoop/current/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.1.jar:/opt/hadoop/current/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.1-tests.jar:/opt/hadoop/current/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.1.jar:/opt/hadoop/current/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.1.jar:/opt/hadoop/current/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.1.jar:/opt/hadoop/current/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.1.jar:/opt/hadoop/current/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.1.jar:/opt/hadoop/current/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.1.jar:/opt/hadoop/current/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.1-tests.jar:/opt/hadoop/current/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.1.jar:/opt/hadoop/current/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.1.jar:/opt/hadoop/current/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.1.jar:/opt/hadoop/current/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.1.jar:/opt/hadoop/current/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.1.jar:/opt/hadoop/current/share/hadoop/yarn:/opt/hadoop/current/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop/current/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/current/share/hadoop/yarn/lib/asm-analysis-9.0.jar:/opt/hadoop/current/share/hadoop/yarn/lib/asm-commons-9.0.jar:/opt/hadoop/current/share/hadoop/yarn/lib/asm-tree-9.0.jar:/opt/hadoop/current/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/current/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/current/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop/current/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop/current/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop/current/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop/current/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop/current/share/hadoop/yarn/lib/jackson-jaxrs-base-2.10.5.jar:/opt/hadoop/current/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.10.5.jar:/opt/hadoop/current/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.10.5.jar:/opt/hadoop/current/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/current/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop/current/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/current/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/opt/hadoop/current/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/opt/hadoop/current/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop/current/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop/current/share/hadoop/yarn/lib/jetty-annotations-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/yarn/lib/jetty-client-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/yarn/lib/jetty-jndi-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/yarn/lib/jetty-plus-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/yarn/lib/jline-3.9.0.jar:/opt/hadoop/current/share/hadoop/yarn/lib/jna-5.2.0.jar:/opt/hadoop/current/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop/current/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop/current/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop/current/share/hadoop/yarn/lib/objenesis-2.6.jar:/opt/hadoop/current/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/opt/hadoop/current/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop/current/share/hadoop/yarn/lib/websocket-api-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/yarn/lib/websocket-client-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/yarn/lib/websocket-common-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/yarn/lib/websocket-server-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/yarn/lib/websocket-servlet-9.4.40.v20210413.jar:/opt/hadoop/current/share/hadoop/yarn/hadoop-yarn-api-3.3.1.jar:/opt/hadoop/current/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.1.jar:/opt/hadoop/current/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.1.jar:/opt/hadoop/current/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.1.jar:/opt/hadoop/current/share/hadoop/yarn/hadoop-yarn-client-3.3.1.jar:/opt/hadoop/current/share/hadoop/yarn/hadoop-yarn-common-3.3.1.jar:/opt/hadoop/current/share/hadoop/yarn/hadoop-yarn-registry-3.3.1.jar:/opt/hadoop/current/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.1.jar:/opt/hadoop/current/share/hadoop/yarn/hadoop-yarn-server-common-3.3.1.jar:/opt/hadoop/current/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.1.jar:/opt/hadoop/current/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.1.jar:/opt/hadoop/current/share/hadoop/yarn/hadoop-yarn-server-router-3.3.1.jar:/opt/hadoop/current/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.1.jar:/opt/hadoop/current/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.1.jar:/opt/hadoop/current/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.1.jar:/opt/hadoop/current/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.1.jar:/opt/hadoop/current/share/hadoop/yarn/hadoop-yarn-services-api-3.3.1.jar:/opt/hadoop/current/share/hadoop/yarn/hadoop-yarn-services-core-3.3.1.jar
[2022-06-01 05:29:33,211] {bash.py:173} INFO - STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a3b9c37a397ad4188041dd80621bdeefc46885f2; compiled by 'ubuntu' on 2021-06-15T05:13Z
[2022-06-01 05:29:33,212] {bash.py:173} INFO - STARTUP_MSG:   java = 1.8.0_332
[2022-06-01 05:29:33,212] {bash.py:173} INFO - ************************************************************/
[2022-06-01 05:29:33,222] {bash.py:173} INFO - 2022-06-01 05:29:33,222 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
[2022-06-01 05:29:33,352] {bash.py:173} INFO - 2022-06-01 05:29:33,350 INFO namenode.NameNode: createNameNode [-format]
[2022-06-01 05:29:33,954] {bash.py:173} INFO - 2022-06-01 05:29:33,953 INFO common.Util: Assuming 'file' scheme for path /opt/hadoop/current/data/namenode in configuration.
[2022-06-01 05:29:33,955] {bash.py:173} INFO - 2022-06-01 05:29:33,954 INFO common.Util: Assuming 'file' scheme for path /opt/hadoop/current/data/namenode in configuration.
[2022-06-01 05:29:33,962] {bash.py:173} INFO - 2022-06-01 05:29:33,962 INFO namenode.NameNode: Formatting using clusterid: CID-58558e57-19ae-47dd-867d-fd1e76ddf01d
[2022-06-01 05:29:34,024] {bash.py:173} INFO - 2022-06-01 05:29:34,024 INFO namenode.FSEditLog: Edit logging is async:true
[2022-06-01 05:29:34,057] {bash.py:173} INFO - 2022-06-01 05:29:34,057 INFO namenode.FSNamesystem: KeyProvider: null
[2022-06-01 05:29:34,059] {bash.py:173} INFO - 2022-06-01 05:29:34,059 INFO namenode.FSNamesystem: fsLock is fair: true
[2022-06-01 05:29:34,060] {bash.py:173} INFO - 2022-06-01 05:29:34,060 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
[2022-06-01 05:29:34,067] {bash.py:173} INFO - 2022-06-01 05:29:34,066 INFO namenode.FSNamesystem: fsOwner                = root (auth:SIMPLE)
[2022-06-01 05:29:34,067] {bash.py:173} INFO - 2022-06-01 05:29:34,066 INFO namenode.FSNamesystem: supergroup             = supergroup
[2022-06-01 05:29:34,067] {bash.py:173} INFO - 2022-06-01 05:29:34,066 INFO namenode.FSNamesystem: isPermissionEnabled    = true
[2022-06-01 05:29:34,067] {bash.py:173} INFO - 2022-06-01 05:29:34,066 INFO namenode.FSNamesystem: isStoragePolicyEnabled = true
[2022-06-01 05:29:34,067] {bash.py:173} INFO - 2022-06-01 05:29:34,066 INFO namenode.FSNamesystem: Determined nameservice ID: hadoop-cluster
[2022-06-01 05:29:34,067] {bash.py:173} INFO - 2022-06-01 05:29:34,066 INFO namenode.FSNamesystem: HA Enabled: true
[2022-06-01 05:29:34,122] {bash.py:173} INFO - 2022-06-01 05:29:34,122 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
[2022-06-01 05:29:34,138] {bash.py:173} INFO - 2022-06-01 05:29:34,138 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
[2022-06-01 05:29:34,138] {bash.py:173} INFO - 2022-06-01 05:29:34,138 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
[2022-06-01 05:29:34,143] {bash.py:173} INFO - 2022-06-01 05:29:34,142 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
[2022-06-01 05:29:34,143] {bash.py:173} INFO - 2022-06-01 05:29:34,143 INFO blockmanagement.BlockManager: The block deletion will start around 2022 Jun 01 05:29:34
[2022-06-01 05:29:34,145] {bash.py:173} INFO - 2022-06-01 05:29:34,145 INFO util.GSet: Computing capacity for map BlocksMap
[2022-06-01 05:29:34,145] {bash.py:173} INFO - 2022-06-01 05:29:34,145 INFO util.GSet: VM type       = 64-bit
[2022-06-01 05:29:34,147] {bash.py:173} INFO - 2022-06-01 05:29:34,147 INFO util.GSet: 2.0% max memory 1.7 GB = 34.4 MB
[2022-06-01 05:29:34,147] {bash.py:173} INFO - 2022-06-01 05:29:34,147 INFO util.GSet: capacity      = 2^22 = 4194304 entries
[2022-06-01 05:29:34,201] {bash.py:173} INFO - 2022-06-01 05:29:34,201 INFO blockmanagement.BlockManager: Storage policy satisfier is disabled
[2022-06-01 05:29:34,202] {bash.py:173} INFO - 2022-06-01 05:29:34,201 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false
[2022-06-01 05:29:34,209] {bash.py:173} INFO - 2022-06-01 05:29:34,208 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.999
[2022-06-01 05:29:34,209] {bash.py:173} INFO - 2022-06-01 05:29:34,209 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
[2022-06-01 05:29:34,209] {bash.py:173} INFO - 2022-06-01 05:29:34,209 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
[2022-06-01 05:29:34,210] {bash.py:173} INFO - 2022-06-01 05:29:34,209 INFO blockmanagement.BlockManager: defaultReplication         = 3
[2022-06-01 05:29:34,210] {bash.py:173} INFO - 2022-06-01 05:29:34,210 INFO blockmanagement.BlockManager: maxReplication             = 512
[2022-06-01 05:29:34,210] {bash.py:173} INFO - 2022-06-01 05:29:34,210 INFO blockmanagement.BlockManager: minReplication             = 1
[2022-06-01 05:29:34,210] {bash.py:173} INFO - 2022-06-01 05:29:34,210 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
[2022-06-01 05:29:34,210] {bash.py:173} INFO - 2022-06-01 05:29:34,210 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms
[2022-06-01 05:29:34,210] {bash.py:173} INFO - 2022-06-01 05:29:34,210 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
[2022-06-01 05:29:34,210] {bash.py:173} INFO - 2022-06-01 05:29:34,210 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
[2022-06-01 05:29:34,241] {bash.py:173} INFO - 2022-06-01 05:29:34,241 INFO namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911
[2022-06-01 05:29:34,241] {bash.py:173} INFO - 2022-06-01 05:29:34,241 INFO namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215
[2022-06-01 05:29:34,241] {bash.py:173} INFO - 2022-06-01 05:29:34,241 INFO namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215
[2022-06-01 05:29:34,241] {bash.py:173} INFO - 2022-06-01 05:29:34,241 INFO namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215
[2022-06-01 05:29:34,258] {bash.py:173} INFO - 2022-06-01 05:29:34,258 INFO util.GSet: Computing capacity for map INodeMap
[2022-06-01 05:29:34,258] {bash.py:173} INFO - 2022-06-01 05:29:34,258 INFO util.GSet: VM type       = 64-bit
[2022-06-01 05:29:34,258] {bash.py:173} INFO - 2022-06-01 05:29:34,258 INFO util.GSet: 1.0% max memory 1.7 GB = 17.2 MB
[2022-06-01 05:29:34,259] {bash.py:173} INFO - 2022-06-01 05:29:34,258 INFO util.GSet: capacity      = 2^21 = 2097152 entries
[2022-06-01 05:29:34,260] {bash.py:173} INFO - 2022-06-01 05:29:34,260 INFO namenode.FSDirectory: ACLs enabled? true
[2022-06-01 05:29:34,260] {bash.py:173} INFO - 2022-06-01 05:29:34,260 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true
[2022-06-01 05:29:34,260] {bash.py:173} INFO - 2022-06-01 05:29:34,260 INFO namenode.FSDirectory: XAttrs enabled? true
[2022-06-01 05:29:34,261] {bash.py:173} INFO - 2022-06-01 05:29:34,261 INFO namenode.NameNode: Caching file names occurring more than 10 times
[2022-06-01 05:29:34,266] {bash.py:173} INFO - 2022-06-01 05:29:34,265 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
[2022-06-01 05:29:34,268] {bash.py:173} INFO - 2022-06-01 05:29:34,268 INFO snapshot.SnapshotManager: SkipList is disabled
[2022-06-01 05:29:34,274] {bash.py:173} INFO - 2022-06-01 05:29:34,274 INFO util.GSet: Computing capacity for map cachedBlocks
[2022-06-01 05:29:34,274] {bash.py:173} INFO - 2022-06-01 05:29:34,274 INFO util.GSet: VM type       = 64-bit
[2022-06-01 05:29:34,274] {bash.py:173} INFO - 2022-06-01 05:29:34,274 INFO util.GSet: 0.25% max memory 1.7 GB = 4.3 MB
[2022-06-01 05:29:34,274] {bash.py:173} INFO - 2022-06-01 05:29:34,274 INFO util.GSet: capacity      = 2^19 = 524288 entries
[2022-06-01 05:29:34,287] {bash.py:173} INFO - 2022-06-01 05:29:34,286 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
[2022-06-01 05:29:34,287] {bash.py:173} INFO - 2022-06-01 05:29:34,286 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
[2022-06-01 05:29:34,288] {bash.py:173} INFO - 2022-06-01 05:29:34,286 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
[2022-06-01 05:29:34,292] {bash.py:173} INFO - 2022-06-01 05:29:34,292 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
[2022-06-01 05:29:34,293] {bash.py:173} INFO - 2022-06-01 05:29:34,292 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
[2022-06-01 05:29:34,295] {bash.py:173} INFO - 2022-06-01 05:29:34,294 INFO util.GSet: Computing capacity for map NameNodeRetryCache
[2022-06-01 05:29:34,295] {bash.py:173} INFO - 2022-06-01 05:29:34,295 INFO util.GSet: VM type       = 64-bit
[2022-06-01 05:29:34,295] {bash.py:173} INFO - 2022-06-01 05:29:34,295 INFO util.GSet: 0.029999999329447746% max memory 1.7 GB = 528.7 KB
[2022-06-01 05:29:34,295] {bash.py:173} INFO - 2022-06-01 05:29:34,295 INFO util.GSet: capacity      = 2^16 = 65536 entries
[2022-06-01 05:29:35,630] {bash.py:173} INFO - 2022-06-01 05:29:35,630 INFO ipc.Client: Retrying connect to server: master02/172.16.238.3:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2022-06-01 05:29:35,630] {bash.py:173} INFO - 2022-06-01 05:29:35,630 INFO ipc.Client: Retrying connect to server: slave01/172.16.238.4:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2022-06-01 05:29:36,631] {bash.py:173} INFO - 2022-06-01 05:29:36,630 INFO ipc.Client: Retrying connect to server: slave01/172.16.238.4:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2022-06-01 05:29:36,631] {bash.py:173} INFO - 2022-06-01 05:29:36,630 INFO ipc.Client: Retrying connect to server: master02/172.16.238.3:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2022-06-01 05:29:37,632] {bash.py:173} INFO - 2022-06-01 05:29:37,631 INFO ipc.Client: Retrying connect to server: slave01/172.16.238.4:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2022-06-01 05:29:37,632] {bash.py:173} INFO - 2022-06-01 05:29:37,631 INFO ipc.Client: Retrying connect to server: master02/172.16.238.3:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2022-06-01 05:29:38,633] {bash.py:173} INFO - 2022-06-01 05:29:38,632 INFO ipc.Client: Retrying connect to server: master02/172.16.238.3:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2022-06-01 05:29:38,633] {bash.py:173} INFO - 2022-06-01 05:29:38,632 INFO ipc.Client: Retrying connect to server: slave01/172.16.238.4:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2022-06-01 05:29:39,633] {bash.py:173} INFO - 2022-06-01 05:29:39,633 INFO ipc.Client: Retrying connect to server: slave01/172.16.238.4:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2022-06-01 05:29:39,634] {bash.py:173} INFO - 2022-06-01 05:29:39,633 INFO ipc.Client: Retrying connect to server: master02/172.16.238.3:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2022-06-01 05:29:40,634] {bash.py:173} INFO - 2022-06-01 05:29:40,633 INFO ipc.Client: Retrying connect to server: slave01/172.16.238.4:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2022-06-01 05:29:40,634] {bash.py:173} INFO - 2022-06-01 05:29:40,634 INFO ipc.Client: Retrying connect to server: master02/172.16.238.3:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2022-06-01 05:29:41,634] {bash.py:173} INFO - 2022-06-01 05:29:41,634 INFO ipc.Client: Retrying connect to server: master02/172.16.238.3:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2022-06-01 05:29:41,635] {bash.py:173} INFO - 2022-06-01 05:29:41,634 INFO ipc.Client: Retrying connect to server: slave01/172.16.238.4:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2022-06-01 05:29:42,636] {bash.py:173} INFO - 2022-06-01 05:29:42,635 INFO ipc.Client: Retrying connect to server: master02/172.16.238.3:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2022-06-01 05:29:42,636] {bash.py:173} INFO - 2022-06-01 05:29:42,635 INFO ipc.Client: Retrying connect to server: slave01/172.16.238.4:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2022-06-01 05:29:43,636] {bash.py:173} INFO - 2022-06-01 05:29:43,636 INFO ipc.Client: Retrying connect to server: slave01/172.16.238.4:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2022-06-01 05:29:43,636] {bash.py:173} INFO - 2022-06-01 05:29:43,636 INFO ipc.Client: Retrying connect to server: master02/172.16.238.3:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2022-06-01 05:29:44,637] {bash.py:173} INFO - 2022-06-01 05:29:44,637 INFO ipc.Client: Retrying connect to server: slave01/172.16.238.4:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2022-06-01 05:29:44,637] {bash.py:173} INFO - 2022-06-01 05:29:44,637 INFO ipc.Client: Retrying connect to server: master02/172.16.238.3:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
[2022-06-01 05:29:44,645] {bash.py:173} INFO - 2022-06-01 05:29:44,642 WARN namenode.NameNode: Encountered exception during format
[2022-06-01 05:29:44,645] {bash.py:173} INFO - org.apache.hadoop.hdfs.qjournal.client.QuorumException: Unable to check if JNs are ready for formatting. 1 successful responses:
[2022-06-01 05:29:44,645] {bash.py:173} INFO - 172.16.238.2:8485: false
[2022-06-01 05:29:44,645] {bash.py:173} INFO - 1 exceptions thrown:
[2022-06-01 05:29:44,645] {bash.py:173} INFO - 172.16.238.4:8485: Call From master01/172.16.238.2 to slave01:8485 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
[2022-06-01 05:29:44,645] {bash.py:173} INFO - 	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
[2022-06-01 05:29:44,645] {bash.py:173} INFO - 	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:305)
[2022-06-01 05:29:44,645] {bash.py:173} INFO - 	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.hasSomeData(QuorumJournalManager.java:282)
[2022-06-01 05:29:44,646] {bash.py:173} INFO - 	at org.apache.hadoop.hdfs.server.common.Storage.confirmFormat(Storage.java:1185)
[2022-06-01 05:29:44,646] {bash.py:173} INFO - 	at org.apache.hadoop.hdfs.server.namenode.FSImage.confirmFormat(FSImage.java:212)
[2022-06-01 05:29:44,646] {bash.py:173} INFO - 	at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1272)
[2022-06-01 05:29:44,646] {bash.py:173} INFO - 	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1724)
[2022-06-01 05:29:44,646] {bash.py:173} INFO - 	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1832)
[2022-06-01 05:29:44,676] {bash.py:173} INFO - 2022-06-01 05:29:44,676 INFO namenode.FSNamesystem: Stopping services started for active state
[2022-06-01 05:29:44,681] {bash.py:173} INFO - 2022-06-01 05:29:44,676 INFO namenode.FSNamesystem: Stopping services started for standby state
[2022-06-01 05:29:44,681] {bash.py:173} INFO - 2022-06-01 05:29:44,676 ERROR namenode.NameNode: Failed to start namenode.
[2022-06-01 05:29:44,681] {bash.py:173} INFO - org.apache.hadoop.hdfs.qjournal.client.QuorumException: Unable to check if JNs are ready for formatting. 1 successful responses:
[2022-06-01 05:29:44,681] {bash.py:173} INFO - 172.16.238.2:8485: false
[2022-06-01 05:29:44,681] {bash.py:173} INFO - 1 exceptions thrown:
[2022-06-01 05:29:44,681] {bash.py:173} INFO - 172.16.238.4:8485: Call From master01/172.16.238.2 to slave01:8485 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
[2022-06-01 05:29:44,681] {bash.py:173} INFO - 	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
[2022-06-01 05:29:44,681] {bash.py:173} INFO - 	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:305)
[2022-06-01 05:29:44,681] {bash.py:173} INFO - 	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.hasSomeData(QuorumJournalManager.java:282)
[2022-06-01 05:29:44,681] {bash.py:173} INFO - 	at org.apache.hadoop.hdfs.server.common.Storage.confirmFormat(Storage.java:1185)
[2022-06-01 05:29:44,681] {bash.py:173} INFO - 	at org.apache.hadoop.hdfs.server.namenode.FSImage.confirmFormat(FSImage.java:212)
[2022-06-01 05:29:44,683] {bash.py:173} INFO - 	at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1272)
[2022-06-01 05:29:44,683] {bash.py:173} INFO - 	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1724)
[2022-06-01 05:29:44,683] {bash.py:173} INFO - 	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1832)
[2022-06-01 05:29:44,683] {bash.py:173} INFO - 2022-06-01 05:29:44,679 INFO util.ExitUtil: Exiting with status 1: org.apache.hadoop.hdfs.qjournal.client.QuorumException: Unable to check if JNs are ready for formatting. 1 successful responses:
[2022-06-01 05:29:44,683] {bash.py:173} INFO - 172.16.238.2:8485: false
[2022-06-01 05:29:44,683] {bash.py:173} INFO - 1 exceptions thrown:
[2022-06-01 05:29:44,684] {bash.py:173} INFO - 172.16.238.4:8485: Call From master01/172.16.238.2 to slave01:8485 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
[2022-06-01 05:29:44,684] {bash.py:173} INFO - 2022-06-01 05:29:44,682 INFO namenode.NameNode: SHUTDOWN_MSG:
[2022-06-01 05:29:44,684] {bash.py:173} INFO - /************************************************************
[2022-06-01 05:29:44,684] {bash.py:173} INFO - SHUTDOWN_MSG: Shutting down NameNode at master01/172.16.238.2
[2022-06-01 05:29:44,684] {bash.py:173} INFO - ************************************************************/
[2022-06-01 05:29:44,720] {bash.py:177} INFO - Command exited with return code 1
[2022-06-01 05:29:44,768] {taskinstance.py:1396} ERROR - Bash command failed. The command returned a non-zero exit code.
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1086, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/usr/local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1260, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/usr/local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1300, in _execute_task
    result = task_copy.execute(context=context)
  File "/usr/local/lib/python3.6/site-packages/airflow/operators/bash.py", line 180, in execute
    raise AirflowException('Bash command failed. The command returned a non-zero exit code.')
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code.
[2022-06-01 05:29:44,770] {taskinstance.py:1440} INFO - Marking task as FAILED. dag_id=ClusterStartUp, task_id=hdfsformat01, execution_date=20220601T052913, start_date=20220601T052932, end_date=20220601T052944
[2022-06-01 05:29:44,856] {local_task_job.py:118} INFO - Task exited with return code 1
